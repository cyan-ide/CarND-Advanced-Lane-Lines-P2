{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_mode = False # show intermediate results\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# ** image transformation thresholds **\n",
    "sobel_ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "# ** masks and warping **\n",
    "warp_source_coordinates = [[150, 720] , [570, 460], [710, 460], [1175, 720]]\n",
    "warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "\n",
    "\n",
    "# ** pixel to real-world conversion **\n",
    "xm_per_pix = 3.7/700 #pixels to real-world\n",
    "\n",
    "# ** sanity checks **\n",
    "max_width_std = 0.1 #max std of length width across all y coords\n",
    "\n",
    "max_lane_width = 4.5 #max width in meters (mean)\n",
    "min_lane_width = 3.4 #max width in meters (mean)\n",
    "\n",
    "bottom_max_lane_width = 4.3 #max width in meters (bottom)\n",
    "bottom_min_lane_width = 3.6 #max width in meters (bottom)\n",
    "\n",
    "not_detected_cnt_thres = 4 #if lane not detected with poly approx method in x frames revert back to histogram method\n",
    "not_detected_cnt_max_thres = 100 #force new poly after x frames even if current frame giving bad results (this is to avoid being locked with one function all the time) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "\n",
    "# images - list of images for calibration\n",
    "# xdim - count of squares horizontally\n",
    "# ydim - count of squares vertically\n",
    "def calibrateCammera(images, xdim = 9, ydim = 6, test = False):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ydim*xdim,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:xdim, 0:ydim].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    \n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (xdim,ydim), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            #testing purpose only\n",
    "            if (test):\n",
    "                cv2.drawChessboardCorners(img, (xdim,ydim), corners, ret)\n",
    "                write_name = 'camera_cal_out/corners_found'+str(idx)+'.jpg'\n",
    "                cv2.imwrite(write_name, img)\n",
    "                plt.imshow(img)\n",
    "                plt.title('Camera Calibration Example Image', fontsize=20)\n",
    "    \n",
    "    # Do camera calibration given object points and image points\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    return mtx, dist\n",
    "\n",
    "def undistort_and_warp(image, mtx, dist):\n",
    "    undistored_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return warp(undistored_img)\n",
    "\n",
    "def gaussian_blur(image, kernel=5):\n",
    "    output = cv2.GaussianBlur(image, (kernel,kernel), 0)\n",
    "    return output\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    \n",
    "#     mask = np.zeros_like(img)\n",
    "#     region_of_interest_vertices = np.array(corners_src, dtype=np.int32)\n",
    "#     cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "#     img = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 1\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, [np.array(vertices, dtype=np.int32)], 1) #ignore_mask_color\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "#    image = undistored_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "def warp(image, image_color = None, warp_source_coords = None, warp_dest_coords = None, test = False):\n",
    "    img = image.copy()\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    #1. get corners for transformation \n",
    "    #source image corners (hardcoded, picked from one image, applied to all other assumign same camera pos)\n",
    "    if (warp_source_coords is None):\n",
    "        warp_source_coords = [[150, 720] , [570, 460], [710, 460], [1175, 720]]\n",
    "    # c) define 4 destination points\n",
    "    if (warp_dest_coords is None):\n",
    "        warp_dest_coords = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "        \n",
    "    corners_src = np.float32(warp_source_coords)\n",
    "    corners_target = np.float32(warp_dest_coords) \n",
    "    \n",
    "    # 2) Convert to grayscale\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # apply region of interest mask (same as warped area)\n",
    "    mask_vertices = corners_src.copy()\n",
    "    mask_vertices[0][0] = mask_vertices[0][0] - 50\n",
    "    mask_vertices[1][0] = mask_vertices[1][0] - 50\n",
    "    mask_vertices[2][0] = mask_vertices[2][0] + 200\n",
    "    mask_vertices[3][0] = mask_vertices[3][0] + 200\n",
    "    img = region_of_interest(img , mask_vertices)    \n",
    "    \n",
    "    # 2. Get transformation matrix based on corners\n",
    "    M = cv2.getPerspectiveTransform(corners_src, corners_target)\n",
    "    Minv = cv2.getPerspectiveTransform(corners_target, corners_src)\n",
    "    \n",
    "    # 3. Perform transformation \n",
    "    # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR) \n",
    "    warped = warped *255\n",
    "    warped = warped.astype('uint8')\n",
    "    #show \n",
    "    if (test):\n",
    "        img = np.dstack(( img.astype('uint8'), img.astype('uint8'), img.astype('uint8'))) * 255 #change b&w mask to rgb\n",
    "        #mark the warp src points\n",
    "        pts = np.array(warp_source_coords, np.int32) \n",
    "        pts = pts.reshape((-1, 1, 2))  \n",
    "        # Using cv2.polylines() method \n",
    "        img = cv2.polylines(img, [pts], isClosed = True, color = (255, 0, 0), thickness = 2)\n",
    "        #mark the dest points\n",
    "        pts_d = np.array(warp_dest_coords, np.int32) \n",
    "        pts_d = pts_d.reshape((-1, 1, 2))  \n",
    "        # Using cv2.polylines() method \n",
    "        warped_overlay = np.dstack(( warped.astype('uint8'), warped.astype('uint8'), warped.astype('uint8'))) #change b&w mask to rgb\n",
    "        warped_overlay = cv2.polylines(warped_overlay, [pts_d], isClosed = True, color = (255, 0, 0), thickness = 2)\n",
    "        \n",
    "        # plot images\n",
    "        if (image_color is not None):\n",
    "            #warp color image\n",
    "            image_color = cv2.warpPerspective(image_color, M, img_size, flags=cv2.INTER_LINEAR) \n",
    "            image_color = cv2.polylines(image_color, [pts_d], isClosed = True, color = (255, 0, 0), thickness = 2)\n",
    "            f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "            f.tight_layout()\n",
    "            ax1.imshow(img)\n",
    "            ax1.set_title('Unwarped, src points', fontsize=30)\n",
    "            # -\n",
    "            ax1_5.imshow(image_color)\n",
    "            ax1_5.set_title('Warped color', fontsize=30)\n",
    "            # -\n",
    "            ax2.imshow(warped_overlay, cmap='gray')\n",
    "            ax2.set_title('Warped gray', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        else:\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "            f.tight_layout()\n",
    "            ax1.imshow(img)\n",
    "            ax1.set_title('Unwarped, src points', fontsize=30)\n",
    "            # -\n",
    "            ax2.imshow(warped, cmap='gray')\n",
    "            ax2.set_title('Warped gray', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    return warped, M, Minv\n",
    "\n",
    "#\n",
    "# undistorted_img - undistored color image\n",
    "# warped - warped lane overlay obtained during lane pixel / curve calculation\n",
    "# Minv - inverse transform for warping 'wraped image'\n",
    "def unwarp(undistorted_img, overlay_warped, Minv):\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(overlay_warped, Minv, (undistorted_img.shape[1], undistorted_img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted_img, 1, newwarp, 0.3, 0)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions relevant to steps in the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transformations (gradient, color transform etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobel filter\n",
    "\n",
    "def sobel_abs_thresh_transform(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    sobel = np.uint8(255*sobel/np.max(sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(sobel)\n",
    "    binary_output[(sobel >= thresh[0]) & (sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    return binary_output\n",
    "\n",
    "def sobel_magnitude_thresh_transform(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    sobel = np.uint8(255*magnitude/np.max(magnitude))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(sobel)\n",
    "    binary_output[(sobel >= mag_thresh[0]) & (sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    return binary_output\n",
    "\n",
    "def sobel_direction_thresh_transform(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    sobelx = np.absolute(sobelx)\n",
    "    sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    gradient = np.arctan2(sobely, sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(gradient)\n",
    "    binary_output[(gradient >= thresh[0]) & (gradient <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    return binary_output\n",
    "\n",
    "def sobel_thresh_transform(image, kernel_size=3, sobel_abs_thresh_x=(40, 100), sobel_abs_thresh_y=(40, 100), sobel_magnitude_thresh=(30, 100), sobel_direction_thresh=(0.7, 1.3)):\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = sobel_abs_thresh_transform(image, orient='x', sobel_kernel=kernel_size, thresh= sobel_abs_thresh_x)\n",
    "    grady = sobel_abs_thresh_transform(image, orient='y', sobel_kernel=kernel_size, thresh= sobel_abs_thresh_y)\n",
    "    mag_binary = sobel_magnitude_thresh_transform(image, sobel_kernel=kernel_size, mag_thresh= sobel_magnitude_thresh)\n",
    "    dir_binary = sobel_direction_thresh_transform(image, sobel_kernel=kernel_size, thresh= sobel_direction_thresh)\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined[((gradx == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    #plt.imshow(combined, cmap='gray')\n",
    "    return(combined)\n",
    "\n",
    "# Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "def hls_thresh_transform(img, thresh=(0, 255), test = False):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    S = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    \n",
    "    H = hls[:,:,0] \n",
    "    h_thres = (170,200) #170, 255\n",
    "    binary_output2 = np.zeros_like(H)\n",
    "    binary_output2[(H > h_thres[0]) & (H <= h_thres[1])] = 1\n",
    "    \n",
    "    l_thres = (170,200)\n",
    "    L = hls[:,:,1]\n",
    "    binary_output3 = np.zeros_like(L)\n",
    "    binary_output3[(L > l_thres[0]) & (L <= l_thres[1])] = 1\n",
    "    if (test):\n",
    "        #TEST\n",
    "\n",
    "        f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(binary_output2, cmap='gray')\n",
    "        ax1.set_title('HLS Thres (H)', fontsize=30)\n",
    "        # -\n",
    "        ax1_5.imshow(binary_output3, cmap='gray')\n",
    "        ax1_5.set_title('HLS Thres (L)', fontsize=30)\n",
    "        # -\n",
    "        ax2.imshow(binary_output, cmap='gray')\n",
    "        ax2.set_title('HLS Thres (S)', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    #END TEST\n",
    "    # 3) Return a binary image of threshold result\n",
    "    #binary_output = np.copy(img) # placeholder line\n",
    "#    return binary_output\n",
    "    return binary_output3\n",
    "\n",
    "def rgb_transform(img, thres=(170,255), test = False):\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    B = img[:,:,2]\n",
    "    \n",
    "    r_thres = (170,200) #170, 255\n",
    "    binary_output1 = np.zeros_like(R)\n",
    "    binary_output1[(R > r_thres[0]) & (R <= r_thres[1])] = 1\n",
    "    \n",
    "    g_thres = (170,200) #170, 255\n",
    "    binary_output2 = np.zeros_like(G)\n",
    "    binary_output2[(G > g_thres[0]) & (G <= g_thres[1])] = 1\n",
    "    \n",
    "    #combine\n",
    "    binary_output = np.zeros_like(R)\n",
    "    binary_output[(binary_output1 == 1) | (binary_output2 == 1)] = 1\n",
    "    \n",
    "    #test\n",
    "    if (test):\n",
    "        b_thres = (170,200) #170, 255\n",
    "        binary_output3 = np.zeros_like(B)\n",
    "        binary_output3[(B > b_thres[0]) & (B <= b_thres[1])] = 1\n",
    "    \n",
    "        f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(binary_output1, cmap='gray')\n",
    "        ax1.set_title('RGB Thres (R)', fontsize=30)\n",
    "        # -\n",
    "        ax1_5.imshow(binary_output2, cmap='gray')\n",
    "        ax1_5.set_title('RGB Thres (G)', fontsize=30)\n",
    "        # -\n",
    "        ax2.imshow(binary_output3, cmap='gray')\n",
    "        ax2.set_title('RGB Thres (B)', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def luv_transform(img, thresh=(225, 255), test = False):\n",
    "\n",
    "    l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "    \n",
    "    l_thresh_min = 225\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "    \n",
    "    #test\n",
    "    if (test):\n",
    "        u_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,1]\n",
    "        u_binary = np.zeros_like(u_channel)\n",
    "        u_binary[(u_channel >= thresh[0]) & (u_channel <= thresh[1])] = 1\n",
    "        \n",
    "        v_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,2]\n",
    "        v_binary = np.zeros_like(v_channel)\n",
    "        v_binary[(v_channel >= thresh[0]) & (v_channel <= thresh[1])] = 1\n",
    "    \n",
    "        f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(l_binary, cmap='gray')\n",
    "        ax1.set_title('LUV Thres (L)', fontsize=30)\n",
    "        # -\n",
    "        ax1_5.imshow(u_binary, cmap='gray')\n",
    "        ax1_5.set_title('LUV Thres (U)', fontsize=30)\n",
    "        # -\n",
    "        ax2.imshow(v_binary, cmap='gray')\n",
    "        ax2.set_title('LUV Thres (V)', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        \n",
    "    return l_binary\n",
    "    \n",
    "\n",
    "def lab_transform(img, thresh=(155, 200), test = False):\n",
    "    b_channel = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]   \n",
    "    \n",
    "    b_thresh_min = 155\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    #test\n",
    "    if (test):\n",
    "        l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,0]\n",
    "        l_binary = np.zeros_like(l_channel)\n",
    "        l_binary[(l_channel >= thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "        \n",
    "        a_channel = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,1]\n",
    "        a_binary = np.zeros_like(a_channel)\n",
    "        a_binary[(a_channel >= thresh[0]) & (a_channel <= thresh[1])] = 1\n",
    "    \n",
    "        f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(l_binary, cmap='gray')\n",
    "        ax1.set_title('LAB Thres (L)', fontsize=30)\n",
    "        # -\n",
    "        ax1_5.imshow(a_binary, cmap='gray')\n",
    "        ax1_5.set_title('LAB Thres (A)', fontsize=30)\n",
    "        # -\n",
    "        ax2.imshow(b_binary, cmap='gray')\n",
    "        ax2.set_title('LAB Thres (B)', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    return b_binary\n",
    "\n",
    "#combined transform for the image, using color and gradient\n",
    "def thresh_transform(img, s_thresh=(170, 255), sx_thresh=(20, 100), test = False):\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    #gradient thresholds\n",
    "    gradient_img = sobel_thresh_transform(img)\n",
    "    # Threshold color channel\n",
    "    hls_img = hls_thresh_transform(img, thresh=s_thresh, test = test)\n",
    "    #rge transform\n",
    "    rgb_img = rgb_transform(img, test = test)\n",
    "    #tests\n",
    "    tst = luv_transform(img, test = test)\n",
    "    tst2 = lab_transform(img, test = test)\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(gradient_img), gradient_img, hls_img)) * 255\n",
    "    \n",
    "    combined = np.zeros_like(gradient_img)\n",
    "#    combined[(gradient_img == 1) | (hls_img == 1) | (rgb_img ==1) ] = 1\n",
    "    combined[(hls_img == 1) | (rgb_img ==1) ] = 1\n",
    "    #show filters\n",
    "    if (test):\n",
    "        f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(hls_img, cmap='gray')\n",
    "        ax1.set_title('HLS Thres', fontsize=30)\n",
    "        # -\n",
    "        ax1_5.imshow(gradient_img, cmap='gray')\n",
    "        ax1_5.set_title('Gradient Thres', fontsize=30)\n",
    "        # -\n",
    "        ax2.imshow(combined, cmap='gray')\n",
    "        ax2.set_title('Joint Thres', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane pixel detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class LaneLine():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # how many times line has not been detected?\n",
    "        self.not_detected_cnt = 0  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img):\n",
    "    # Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "\n",
    "    # Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "\n",
    "def measure_curvature_pixels(left_fit, right_fit, ploty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def find_lane_pixels(binary_warped): \n",
    "    # ----- histogram -----\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # ----- sliding window -----\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero() #get non zero pixels from the image matrix (size 1028x1028)\n",
    "    nonzeroy = np.array(nonzero[0]) # x-coords of non-zero pixels\n",
    "    nonzerox = np.array(nonzero[1]) # y-coords of non-zero pixels\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin # Update this\n",
    "        win_xleft_high = leftx_current + margin # Update this\n",
    "        win_xright_low = rightx_current - margin # Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        # good_left_inds / good_right_indx - stores indices in the nonzerox/nonzeroy arrays (which are also arrays of indices but in the image matrix)\n",
    "        good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high) & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox < win_xright_high) & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "        pass # Remove this when you add your function\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img, histogram\n",
    "\n",
    "\n",
    "def draw_lane(binary_warped, left_fit, right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "    \n",
    "    # draw the lines on empty image for output\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    return color_warp \n",
    "\n",
    "        \n",
    "def fit_polynomial(binary_warped, test = False):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img, histogram = find_lane_pixels(binary_warped)\n",
    "    \n",
    "#     if (len(lefty) == 0) or (len(righty) == 0): #secure against no points given (possible if searched area was empty after all the filters)\n",
    "#         return None, None, None, None, None\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    if (len(lefty) != 0) and (len(righty) != 0):\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        try:\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        except TypeError:\n",
    "            # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            left_fitx = 1*ploty**2 + 1*ploty\n",
    "            right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "        ## Visualization ##\n",
    "        # Colors in the left and right lane regions\n",
    "        if (test):\n",
    "            out_img[lefty, leftx] = [255, 0, 0]\n",
    "            out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "            # Plots the left and right polynomials on the lane lines\n",
    "        #     if (test):\n",
    "    #         plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #         plt.plot(right_fitx, ploty, color='yellow')\n",
    "            # ------\n",
    "            histogram = histogram.astype('float32') / 255\n",
    "            f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "            f.tight_layout()\n",
    "            ax1.imshow(np.int_(np.logical_not(binary_warped)), cmap='gray')\n",
    "            ax1.plot(binary_warped.shape[0]-histogram, color='red')\n",
    "            ax1.set_title('Histogram', fontsize=30)\n",
    "            # -\n",
    "            ax1_5.imshow(out_img) #, cmap='gray'\n",
    "            ax1_5.set_title('Pixel find with moving window', fontsize=30)\n",
    "            # -\n",
    "            ax2.imshow(out_img) #, cmap='gray'\n",
    "            ax2.plot(left_fitx, ploty, color='yellow')\n",
    "            ax2.plot(right_fitx, ploty, color='yellow')\n",
    "            ax2.set_title('Fitted line', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "        # draw the lines on empty image for output\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        return color_warp, left_fit, right_fit, ploty\n",
    "    else: #if no pixels detected at all\n",
    "        if (test):\n",
    "            # ------\n",
    "            f, (ax1, ax1_5, ax2) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "            ax1.imshow(color_warp, cmap='gray')\n",
    "            ax1.set_title('Histogram', fontsize=30)\n",
    "            # -\n",
    "            ax1_5.imshow(color_warp) #, cmap='gray'\n",
    "            ax1_5.set_title('Pixel find with moving window', fontsize=30)\n",
    "            # -\n",
    "            ax2.imshow(color_warp) #, cmap='gray'\n",
    "            ax2.set_title('Fitted line', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        return color_warp ,None, None, None\n",
    "\n",
    "# ------------ fit if previous frame available -----------------\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    if (len(lefty) == 0) or (len(righty) == 0): #secure against no points given (possible if searched area was empty after all the filters)\n",
    "        return None, None, None, None, None\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty, left_fit, right_fit\n",
    "\n",
    "def search_around_poly(binary_warped, prev_left_fit, prev_right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    \n",
    "    #old\n",
    "#     good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high) & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "#     good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox < win_xright_high) & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "\n",
    "#     print(\"len(nonzero):\"+str(len(nonzero))+ \" ;len(nonzeroy):\"+str(len(nonzeroy)) + \" ;len(nonzerox):\" + str(len(nonzerox)))\n",
    "#     print(\"prev_left_fit:\"+str(prev_left_fit))\n",
    "#     print(\"prev_left_fit[0]:\"+str(prev_left_fit[0])+ \" ;prev_left_fit[1]:\"+str(prev_left_fit[1]) + \" ;prev_left_fit[2]:\" + str(prev_left_fit[2]) )\n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (prev_left_fit[0]*(nonzeroy**2) + prev_left_fit[1]*nonzeroy + \n",
    "                    prev_left_fit[2] - margin)) & (nonzerox < (prev_left_fit[0]*(nonzeroy**2) + \n",
    "                    prev_left_fit[1]*nonzeroy + prev_left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (prev_right_fit[0]*(nonzeroy**2) + prev_right_fit[1]*nonzeroy + \n",
    "                    prev_right_fit[2] - margin)) & (nonzerox < (prev_right_fit[0]*(nonzeroy**2) + \n",
    "                    prev_right_fit[1]*nonzeroy + prev_right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty, left_fit, right_fit = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    if left_fitx is not None:\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "        # Plot the polynomial lines onto the image\n",
    "    #     plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #     plt.plot(right_fitx, ploty, color='yellow')\n",
    "        ## End visualization steps ##\n",
    "\n",
    "        # draw the lines on empty image for output\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "#    return result\n",
    "    return color_warp, left_fit, right_fit, ploty\n",
    "\n",
    "#return avg line distnace or -1 if distance changes abruptly at some section \n",
    "def line_distance(left_fit, right_fit, ploty, xm_per_pix = 3.7/700):\n",
    "    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    diff_fitx =  right_fitx - left_fitx\n",
    "    #print(diff_fitx)\n",
    "    mean_x = np.mean(diff_fitx)\n",
    "    std_x = np.std(diff_fitx)\n",
    "    z_score = (diff_fitx - mean_x) / std_x\n",
    "    z_score_max = np.max(z_score)\n",
    "    #print(\"avg[m]: \"+str(mean_x*xm_per_pix)+\", std:\"+str(std_x),\", max_z:\"+str(z_score_max)+\", std/mean:\"+str(std_x/mean_x)+\", top[m]:\"+str(diff_fitx[0]*xm_per_pix)+\", bottom[m]:\"+str(diff_fitx[len(diff_fitx)-1]*xm_per_pix))\n",
    "    #print(z_score)\n",
    "    if (std_x/mean_x) >= 0.1: #look for abnormal standard deviation distance between lanes (== non parallel)\n",
    "        return -1\n",
    "    elif ((mean_x*xm_per_pix)> max_lane_width) or ((mean_x*xm_per_pix)< min_lane_width) : # check for abnormal lane width in meters\n",
    "        return -2\n",
    "    elif ( diff_fitx[len(diff_fitx)-1]*xm_per_pix > bottom_max_lane_width) or ( diff_fitx[len(diff_fitx)-1]*xm_per_pix < bottom_min_lane_width):\n",
    "        return -3\n",
    "    elif ( diff_fitx[0]*xm_per_pix > bottom_max_lane_width) or ( diff_fitx[0]*xm_per_pix < bottom_min_lane_width):\n",
    "        return -3\n",
    "    else:\n",
    "        return np.mean(diff_fitx)\n",
    "\n",
    "def lane_line_sanity_check(new_left_fit, new_right_fit, lane_left, lane_right, ploty, xm_per_pix = 3.7/700):\n",
    "    if (new_left_fit is None) or (new_right_fit is None):\n",
    "        return -5\n",
    "    #1. check if lines have similar curvature\n",
    "    left_curverad_m, right_curverad_m = measure_curvature_real(new_left_fit, new_right_fit, ploty)\n",
    "    left_curverad, right_curverad = measure_curvature_pixels(new_left_fit, new_right_fit, ploty)\n",
    "    \n",
    "#     print(\"curveture[m], l:\"+str(left_curverad*xm_per_pix)+ \", r:\"+str(right_curverad*xm_per_pix)+ \", l-r:\"+str((left_curverad-right_curverad)*xm_per_pix) ) \n",
    "#     print(\"curveture[m_v2], l:\"+str(left_curverad_m)+ \", r:\"+str(right_curverad_m)+ \", l-r:\"+str((left_curverad_m-right_curverad_m)) ) \n",
    "    #print(\"curveture[px], l:\"+str(left_curverad)+ \", r:\"+str(right_curverad)+ \", l-r:\"+str((left_curverad-right_curverad))+ \", l-r/l:\"+str( ((left_curverad-right_curverad)/left_curverad)) + \", l-r/r:\"+str( ((left_curverad-right_curverad)/right_curverad)) ) \n",
    "    #2+3: \n",
    "    # - check if lines are separated by approximately the right distance horizontally\n",
    "    # - check if lines are roughly parallel\n",
    "#     print(\"parallel check:\")\n",
    "    # -- left\n",
    "    a_left = new_left_fit[0]\n",
    "    b_left = new_left_fit[1]\n",
    "    c_left = new_left_fit[2]\n",
    "    # -- right\n",
    "    a_right = new_right_fit[0]\n",
    "    b_right = new_right_fit[1]\n",
    "    c_right = new_right_fit[2]\n",
    "    # calc diff\n",
    "    a_diff = a_left - a_right\n",
    "    b_diff = b_left - b_right\n",
    "    c_diff = c_left - c_right\n",
    "    #curverure difference measured as difference in function parameters\n",
    "    #print(\"a_diff: \"+str(a_diff)+\" - b_diff: \"+str(b_diff)+\" - c_diff: \"+str(c_diff) )\n",
    "#     print(\"a_diff(l): \"+str(a_diff/a_left)+\" - b_diff(l): \"+str(b_diff/b_left)+\" - c_diff(l): \"+str(c_diff/c_left) )\n",
    "#     print(\"a_diff(r): \"+str(a_diff/a_right)+\" - b_diff(r): \"+str(b_diff/b_right)+\" - c_diff(r): \"+str(c_diff/c_right) )\n",
    "#     if (a_diff/a_left) > a_thres or (b_diff/b_left) > a_thres or (c_diff/c_left) > a_thres:\n",
    "        \n",
    "#         return -4\n",
    "#     if (a_diff/a_right) > a_thres or (b_diff/b_right) > a_thres or (c_diff/c_right) > a_thres:\n",
    "#         return -5\n",
    "    \n",
    "    #parallel check v2 (check distance for all pixels, look at mean/std/z-score)\n",
    "    #print(\"dist check:\")\n",
    "    lane_dist = line_distance(new_left_fit, new_right_fit, ploty)\n",
    "    if  lane_dist < 0:\n",
    "        return lane_dist\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def fit_polynomial_multiframe(binary_warped, lane_left = None , lane_right = None, test = False):\n",
    "    \n",
    "#     #test\n",
    "#     output, left_fit, right_fit, ploty = fit_polynomial(binary_warped, test = test)\n",
    "#     #write to Lane objects\n",
    "#     if (lane_left is None):\n",
    "#         lane_left = LaneLine()\n",
    "#     if (lane_right is None):\n",
    "#         lane_right = LaneLine()\n",
    "\n",
    "#     lane_left.current_fit = left_fit\n",
    "#     lane_right.current_fit = right_fit\n",
    "#     test_sanity = lane_line_sanity_check(left_fit, right_fit, lane_left, lane_right, ploty)\n",
    "#     return  output, lane_left, lane_right, ploty, test_sanity\n",
    "    \n",
    "    #print(str(binary_warped.shape[0])+\"x\"+str(binary_warped.shape[1]))\n",
    "    #get lane lines\n",
    "    \n",
    "    if (lane_left is None or lane_right is None): #if previous not available do histogram\n",
    "        output, left_fit, right_fit, ploty = fit_polynomial(binary_warped, test = test)\n",
    "        #write to Lane objects\n",
    "        if (lane_left is None):\n",
    "            lane_left = LaneLine()\n",
    "        if (lane_right is None):\n",
    "            lane_right = LaneLine()\n",
    "    else: #if previous available search around the polynomial calculated in prior frame\n",
    "        output, left_fit, right_fit, ploty = search_around_poly(binary_warped, prev_left_fit = lane_left.current_fit , prev_right_fit = lane_right.current_fit )\n",
    "        if (left_fit is not None):\n",
    "            test_sanity = lane_line_sanity_check(left_fit, right_fit, lane_left, lane_right, ploty) \n",
    "            if (test_sanity<0) and ( (lane_left.not_detected_cnt >= not_detected_cnt_thres) or (lane_right.not_detected_cnt >= not_detected_cnt_thres)):\n",
    "                output, left_fit, right_fit, ploty = fit_polynomial(binary_warped, test = test)\n",
    "        else:\n",
    "            output, left_fit, right_fit, ploty = fit_polynomial(binary_warped, test = test)\n",
    "        #check if lines correct, if not do histogram\n",
    "    \n",
    "    #do some best effort checks if lines are correct\n",
    "    \n",
    "    #if not correct use prior frame polynomial\n",
    "            \n",
    "    test_sanity = lane_line_sanity_check(left_fit, right_fit, lane_left, lane_right, ploty)\n",
    "\n",
    "    #update curve only if lane detected correctly (or if first frame), otherwise fall back to old calculation\n",
    "#     print(\"test_sanity:\"+str(test_sanity))\n",
    "#     print(\"left_fit:\")\n",
    "#     print(left_fit)\n",
    "#     if (lane_left is not None):\n",
    "#         print(\"left_fit_curr:\")\n",
    "#         print(lane_left.current_fit)\n",
    "    if (test_sanity>=0) or (len(lane_left.current_fit)<=1) or ((lane_left.not_detected_cnt >= not_detected_cnt_max_thres) and (left_fit is not None) and (right_fit is not None)): \n",
    "        lane_left.current_fit = left_fit\n",
    "        lane_left.ally = ploty\n",
    "        \n",
    "        lane_right.current_fit = right_fit\n",
    "        lane_right.ally = ploty\n",
    "        \n",
    "        #zero detection counter\n",
    "        lane_left.not_detected_cnt = 0\n",
    "        lane_right.not_detected_cnt = 0\n",
    "    else:\n",
    "        #print(\"using prior curve!!\")\n",
    "        #mark that lanes were not detected\n",
    "        lane_left.not_detected_cnt += 1\n",
    "        lane_right.not_detected_cnt += 1\n",
    "#     if (not test_sanity):\n",
    "#         print(\"##\")\n",
    "#         cv2.rectangle(output,(100,100), (50,50),(255,0,0), -1) \n",
    "\n",
    "    output = draw_lane(binary_warped, lane_left.current_fit, lane_right.current_fit)\n",
    "    \n",
    "    return output, lane_left, lane_right, test_sanity #, ploty\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvature of the lane and vehicle position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(left_fit, right_fit, ploty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    \n",
    "    if (left_fit is None) or (right_fit is None): #error handling\n",
    "        return 0,0\n",
    "    \n",
    "#     print(left_fit)\n",
    "#     print(right_fit)\n",
    "#     print(\"--\")\n",
    "#     print(ploty)\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/1280 #720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Start by generating our fake example data\n",
    "    # Make sure to feed in your real data instead in your project!\n",
    "    #ploty, left_fit_cr, right_fit_cr = generate_data(ym_per_pix, xm_per_pix)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to store both lanes and pass to pipeline for updating\n",
    "class LaneLines():\n",
    "    def __init__(self):\n",
    "        self.update_data = False # flag if data should be updated based on new frames or not\n",
    "        #left/ right lane data\n",
    "        self.lane_left = None  \n",
    "        self.lane_right = None\n",
    "    \n",
    "\n",
    "\n",
    "# image - image to analyse and annotate\n",
    "# mtx, dist - parameters for correcting camera distortion\n",
    "# lane_left - left lane data if available from previous frames\n",
    "# lane_right - right lane data if available from previous frames\n",
    "def extract_lane_boundries(image,mtx, dist, lane_data = LaneLines(), test = False):\n",
    "    image_org = image.copy()\n",
    "    output = image.copy()\n",
    "    # 2. Apply a distortion correction to raw images.\n",
    "    undistorted_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    output = undistorted_img.copy()\n",
    "    # 2.5 apply blur\n",
    "    output = gaussian_blur(output, kernel=3)\n",
    "    # 3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    #output = sobel_thresh_transform(output)\n",
    "    output = thresh_transform(output, test = test)\n",
    "    # 4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "    output, M, Minv = warp(output, image_color = image_org, warp_source_coords = warp_source_coordinates, warp_dest_coords = warp_destination_coordinates, test = test)\n",
    "    # 5. Detect lane pixels and fit to find the lane boundary.\n",
    "    output, lane_left, lane_right,tst = fit_polynomial_multiframe(output, lane_left = lane_data.lane_left , lane_right = lane_data.lane_right, test = test) #, ploty\n",
    "    # 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "    left_curverad, right_curverad = measure_curvature_real(lane_left.current_fit, lane_right.current_fit, lane_left.ally) #\n",
    "    # 7. Warp the detected lane boundaries back onto the original image.\n",
    "    output = unwarp(undistorted_img, output, Minv)\n",
    "    # 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "    #print(left_curverad, right_curverad)\n",
    "    if (tst<0):\n",
    "        if (tst == -3): #bad bottom width\n",
    "            cv2.rectangle(output,(100,100), (50,50),(0,0,255), -1) \n",
    "        elif (tst == -2): #bad width\n",
    "            cv2.rectangle(output,(100,100), (50,50),(0,255,0), -1) \n",
    "        else: #non-parallel\n",
    "            cv2.rectangle(output,(100,100), (50,50),(255,0,0), -1) \n",
    "    \n",
    "    if (lane_data.update_data == True):\n",
    "        lane_data.lane_left = lane_left\n",
    "        lane_data.lane_right = lane_right\n",
    "    \n",
    "    return output #, lane_left, lane_right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test_images/project_video-00600.jpg\n",
      "Processing test_images/challenge_video-00050.jpg\n",
      "Processing test_images/project_video-00599.jpg\n",
      "Processing test_images/challenge_video-00027.jpg\n"
     ]
    }
   ],
   "source": [
    "#modify some parameters from defaults\n",
    "verbose_mode = False\n",
    "#challenge vid coords\n",
    "# warp_source_coordinates = [[240, 720] , [580, 490], [740, 490], [1125, 720]]\n",
    "# warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "\n",
    "#regular video coords\n",
    "warp_source_coordinates = [[150, 720] , [570, 460], [710, 460], [1175, 720]]\n",
    "warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "\n",
    "#1. prep - calibrate cammera\n",
    "\n",
    "# Make a list of calibration images\n",
    "camera_calib_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "mtx, dist = calibrateCammera(camera_calib_images, test = verbose_mode)\n",
    "\n",
    "#2. prep - read-in data\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "#3. run pipeline for all images\n",
    "\n",
    "lane_data = LaneLines()\n",
    "\n",
    "for idx, fpath in enumerate(test_images):\n",
    "    print('Processing '+fpath)\n",
    "    img = cv2.imread(fpath)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_src = fpath #test_images[3]\n",
    "    img = mpimg.imread(img_src)\n",
    "    img_out = extract_lane_boundries(img, mtx, dist, lane_data = lane_data, test = verbose_mode)\n",
    "    \n",
    "    if (verbose_mode):\n",
    "        #visualise result\n",
    "        # Visualize\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        # ax1.imshow(output2, cmap='gray')\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        ax2.imshow(img_out, cmap='gray')\n",
    "        ax2.set_title('Processed Image', fontsize=30)\n",
    "\n",
    "    #4. write output\n",
    "    filename =os.path.basename(fpath)\n",
    "    filename_noext = os.path.splitext(filename)[0]\n",
    "    write_name = \"output_images/\"+filename_noext+\".jpg\"\n",
    "    cv2.imwrite(write_name, cv2.cvtColor(img_out, cv2.COLOR_RGB2BGR))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test still frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose_mode = False\n",
    "#challenge vid coords\n",
    "warp_source_coordinates = [[240, 720] , [580, 490], [740, 490], [1125, 720]]\n",
    "warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "not_detected_cnt_max_thres = 8\n",
    "\n",
    "#regular video coords\n",
    "# warp_source_coordinates = [[150, 720] , [570, 460], [710, 460], [1175, 720]]\n",
    "# warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "# not_detected_cnt_max_thres = 100\n",
    "\n",
    "#1. prep - calibrate cammera\n",
    "\n",
    "# Make a list of calibration images\n",
    "camera_calib_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "mtx, dist = calibrateCammera(camera_calib_images, test = verbose_mode)\n",
    "\n",
    "#2. prep - read-in data\n",
    "# test_images = sorted(glob.glob('test_video3/*.jpg'))\n",
    "test_images = sorted(glob.glob('challenge_video/*.jpg'))\n",
    "# test_images = sorted(glob.glob('harder_challenge_video/*.jpg'))\n",
    "\n",
    "\n",
    "#3. run pipeline for all images\n",
    "\n",
    "#lane_left = None\n",
    "#lane_right = None\n",
    "lane_data = LaneLines()\n",
    "lane_data.update_data = True\n",
    "\n",
    "for idx, fpath in enumerate(test_images):\n",
    "    print('Processing '+fpath)\n",
    "#     if (fpath == \"challenge_video/challenge_video-00130.jpg\"):\n",
    "#         verbose_mode = True\n",
    "    img = cv2.imread(fpath)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_src = fpath #test_images[3]\n",
    "    img = mpimg.imread(img_src)\n",
    "    #, lane_left, lane_right\n",
    "    img_out = extract_lane_boundries(img, mtx, dist, lane_data = lane_data, test = verbose_mode) #\n",
    "    \n",
    "    if (verbose_mode):\n",
    "        #visualise result\n",
    "        # Visualize\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        # ax1.imshow(output2, cmap='gray')\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        ax2.imshow(img_out, cmap='gray')\n",
    "        ax2.set_title('Processed Image', fontsize=30)\n",
    "\n",
    "    #4. write output\n",
    "    filename =os.path.basename(fpath)\n",
    "    filename_noext = os.path.splitext(filename)[0]\n",
    "#     write_name = \"harder_challenge_video_out/\"+filename_noext+\".jpg\"\n",
    "    write_name = \"challenge_video_out/\"+filename_noext+\".jpg\"\n",
    "#     write_name = \"test_video_out3/\"+filename_noext+\".jpg\"\n",
    "    cv2.imwrite(write_name, cv2.cvtColor(img_out, cv2.COLOR_RGB2BGR))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, mtx, dist, lane_data = lane_data):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    #return image\n",
    "    return extract_lane_boundries(image,mtx, dist, lane_data = lane_data, test = verbose_mode)\n",
    "#    return detect_lanes(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 2/1260 [00:00<01:42, 12.26it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video project_video_annotated.mp4.\n",
      "Moviepy - Writing video project_video_annotated.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready project_video_annotated.mp4\n",
      "CPU times: user 15min 11s, sys: 1min, total: 16min 11s\n",
      "Wall time: 4min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "verbose_mode = False\n",
    "\n",
    "#calibrate cammera\n",
    "camera_calib_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "mtx, dist = calibrateCammera(camera_calib_images, test = verbose_mode)\n",
    "\n",
    "#init lane data\n",
    "lane_data = LaneLines()\n",
    "lane_data.update_data = True\n",
    "#pipeline settings specific for first video\n",
    "warp_source_coordinates = [[150, 720] , [570, 460], [710, 460], [1175, 720]]\n",
    "warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "not_detected_cnt_max_thres = 100\n",
    "\n",
    "\n",
    "#process video\n",
    "output_video_path = 'project_video_annotated.mp4'\n",
    "#white_output = 'solidWhiteRight666.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "input_video = VideoFileClip(\"project_video.mp4\")\n",
    "output_video = input_video.fl_image(lambda image: process_image(image, mtx, dist, lane_data)) #NOTE: this function expects color images!!\n",
    "#white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time output_video.write_videofile(output_video_path, audio=False) #, codec='libvpx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challanging Video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 2/485 [00:00<00:39, 12.35it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video challenge_video_annotated.mp4.\n",
      "Moviepy - Writing video challenge_video_annotated.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready challenge_video_annotated.mp4\n",
      "CPU times: user 5min 33s, sys: 22.8 s, total: 5min 56s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "verbose_mode = False\n",
    "\n",
    "#calibrate cammera\n",
    "camera_calib_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "mtx, dist = calibrateCammera(camera_calib_images, test = verbose_mode)\n",
    "\n",
    "#init lane data\n",
    "lane_data = LaneLines()\n",
    "lane_data.update_data = True\n",
    "#pipeline settings specific for challenge video\n",
    "warp_source_coordinates = [[240, 720] , [580, 490], [740, 490], [1125, 720]]\n",
    "warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "not_detected_cnt_max_thres = 8\n",
    "\n",
    "#process video\n",
    "output_video_path = 'challenge_video_annotated.mp4'\n",
    "#white_output = 'solidWhiteRight666.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "input_video = VideoFileClip(\"challenge_video.mp4\")\n",
    "output_video = input_video.fl_image(lambda image: process_image(image, mtx, dist, lane_data)) #NOTE: this function expects color images!!\n",
    "#white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time output_video.write_videofile(output_video_path, audio=False) #, codec='libvpx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder challanging Video test (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 2/1199 [00:00<01:51, 10.76it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video harder_challenge_video_annotated.mp4.\n",
      "Moviepy - Writing video harder_challenge_video_annotated.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready harder_challenge_video_annotated.mp4\n",
      "CPU times: user 15min 24s, sys: 1min 7s, total: 16min 32s\n",
      "Wall time: 4min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "verbose_mode = False\n",
    "\n",
    "#calibrate cammera\n",
    "camera_calib_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "mtx, dist = calibrateCammera(camera_calib_images, test = verbose_mode)\n",
    "\n",
    "#init lane data\n",
    "lane_data = LaneLines()\n",
    "lane_data.update_data = True\n",
    "#pipeline settings specific for challenge video\n",
    "warp_source_coordinates = [[240, 720] , [580, 490], [740, 490], [1125, 720]]\n",
    "warp_destination_coordinates = [[250,  720], [250,    0],  [1065,   0], [1065, 720]]\n",
    "not_detected_cnt_max_thres = 8\n",
    "\n",
    "#process video\n",
    "output_video_path = 'harder_challenge_video_annotated.mp4'\n",
    "#white_output = 'solidWhiteRight666.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "input_video = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "output_video = input_video.fl_image(lambda image: process_image(image, mtx, dist, lane_data)) #NOTE: this function expects color images!!\n",
    "#white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time output_video.write_videofile(output_video_path, audio=False) #, codec='libvpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
